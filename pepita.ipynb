{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PEPITA network","metadata":{}},{"cell_type":"code","source":"# Install torchattacks library if not installed\n!pip install torchattacks","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This code defines and trains the PEPITA neural network for MNIST classification, using adversarial attacks for robustness evaluation. ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport numpy as np\nimport torch.cuda\nimport torchattacks\n\n# Define the PEPITA network with flexible hyperparameters\nclass PEPITANetwork(nn.Module):\n    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate=0.1):\n        super(PEPITANetwork, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_sizes[0], bias=False)\n        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1], bias=False)\n        self.fc3 = nn.Linear(hidden_sizes[1], output_size, bias=False)\n        self.dropout_rate = dropout_rate\n        \n        # He initialization\n        fc1_limit = np.sqrt(6.0 / input_size)\n        torch.nn.init.uniform_(self.fc1.weight, a=-fc1_limit, b=fc1_limit)\n        fc2_limit = np.sqrt(6.0 / hidden_sizes[0])\n        torch.nn.init.uniform_(self.fc2.weight, a=-fc2_limit, b=fc2_limit)\n        fc3_limit = np.sqrt(6.0 / hidden_sizes[1])\n        torch.nn.init.uniform_(self.fc3.weight, a=-fc3_limit, b=fc3_limit)\n\n    def forward(self, x, do_masks=None):\n        x = F.relu(self.fc1(x))\n        if do_masks is not None:\n            x = x * do_masks[0]  # Apply custom dropout mask\n        x = F.relu(self.fc2(x))\n        if do_masks is not None:\n            x = x * do_masks[1]  # Apply custom dropout mask\n        x = F.softmax(self.fc3(x), dim=1)\n        return x\n\n# Initialize feedback matrix (B)\ndef initialize_feedback_matrix(input_size, output_size, scale=0.05, device='cpu'):\n    sd = np.sqrt(6.0 / input_size)\n    B = (torch.rand(input_size, output_size) * 2 * sd - sd) * scale\n    return B.to(device)\n\n# Setup data loaders (MNIST dataset)\ndef get_dataloaders(batch_size=16):\n    transform = transforms.Compose([transforms.ToTensor()])\n    trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n    testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n    return trainloader, testloader\n\n# Validation function to evaluate model performance\ndef validate_pepita(net, dataloader, device, criterion):\n    net.eval()  # Set network to evaluation mode\n    running_loss = 0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, target in dataloader:\n            inputs = inputs.view(inputs.size(0), -1).to(device)  # Flatten inputs\n            target = target.to(device)\n            outputs = net(inputs)  # Forward pass\n            loss = criterion(outputs, target)\n            running_loss += loss.item()\n\n            # Accuracy calculation\n            _, predicted = torch.max(outputs.data, 1)\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n    \n    accuracy = 100 * correct / total\n    return running_loss / len(dataloader), accuracy\n\n# Adversarial attack evaluation function\ndef evaluate_model(net, dataloader, device, attack_method=None):\n    \"\"\"\n    Evaluate the model on clean or adversarial examples.\n    attack_method: If None, clean data is used. If 'PGD' or 'FGSM', adversarial attack is applied using torchattacks.\n    \"\"\"\n    net.eval()\n    correct = 0\n    total = 0\n\n    # Set up adversarial attack if specified\n    if attack_method == 'PGD':\n        attack = torchattacks.PGD(net, eps=0.3, alpha=2/255, steps=40)\n    elif attack_method == 'FGSM':\n        attack = torchattacks.FGSM(net, eps=0.3)\n    else:\n        attack = None\n\n    for inputs, target in dataloader:\n        inputs = inputs.view(inputs.size(0), -1).to(device)\n        target = target.to(device)\n\n        if attack:\n            # Ensure inputs require gradients for adversarial attack generation\n            inputs.requires_grad_()\n            # Apply adversarial attack without torch.no_grad()\n            inputs = attack(inputs, target) \n\n        # Evaluation should be inside torch.no_grad()\n        with torch.no_grad():\n            outputs = net(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f'Accuracy on {\"adversarial\" if attack else \"clean\"} examples: {accuracy:.2f}%')\n\n# PEPITA training loop with memory optimization and hyperparameter control\ndef train_pepita(net, trainloader, valloader, config):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    net.to(device)\n    \n    # Hyperparameters from config\n    epochs = config['epochs']\n    eta = config['learning_rate']\n    gamma = config['momentum']\n    batch_size = config['batch_size']\n    keep_rate = config['keep_rate']\n    optimizer_type = config['optimizer_type']\n    \n    # Initialize feedback matrix B for MNIST\n    B = initialize_feedback_matrix(28*28, 10, device=device)\n\n    criterion = nn.CrossEntropyLoss()\n\n    # Momentum optimizer setup\n    v_w_all = [torch.zeros(w.shape).to(device) for w in net.parameters()]\n    \n    for epoch in range(epochs):\n        if epoch in config['lr_decay_epochs']:  # Learning rate decay\n            eta *= config['lr_decay_factor']\n            \n        running_loss = 0\n        net.train()  # Set network to training mode\n        for i, data in enumerate(trainloader, 0):\n            inputs, target = data\n            inputs = inputs.view(inputs.size(0), -1).to(device)  # Flatten MNIST input and move to device\n            target = target.to(device)  # Move target to device\n\n            target_onehot = F.one_hot(target, num_classes=10).float().to(device)\n\n            # Dropout masks for the two forward passes\n            do_masks = []\n            if keep_rate < 1:\n                for layer in [net.fc1, net.fc2]:\n                    mask = Variable(torch.ones(inputs.shape[0], layer.out_features).bernoulli_(keep_rate)).to(device) / keep_rate\n                    do_masks.append(mask)\n\n            # Disable gradient tracking to save memory\n            with torch.no_grad():\n\n                # Forward pass 1 (standard forward pass)\n                outputs = net(inputs, do_masks=do_masks)\n\n                # Compute the error (difference between output and target)\n                error_signal = outputs - target_onehot\n\n                # Modify the input with the error and feedback matrix\n                error_input = error_signal @ B.T\n                mod_inputs = inputs + error_input\n\n                # Forward pass 2 (modulated forward pass)\n                mod_outputs = net(mod_inputs, do_masks=do_masks)\n\n                # Compute weight updates\n                delta_w_all = []\n                for l_idx, layer in enumerate([net.fc1, net.fc2, net.fc3]):\n                    if l_idx == 0:\n                        delta_w = -(F.relu(net.fc1(inputs)) - F.relu(net.fc1(mod_inputs))).T @ inputs\n                    elif l_idx == 1:\n                        delta_w = -(F.relu(net.fc2(F.relu(net.fc1(inputs)))) - F.relu(net.fc2(F.relu(net.fc1(mod_inputs))))).T @ F.relu(net.fc1(mod_inputs))\n                    else:\n                        delta_w = -(error_signal.T @ F.relu(net.fc2(F.relu(net.fc1(mod_inputs)))))\n\n                    delta_w_all.append(delta_w / batch_size)\n\n                # Apply the weight changes\n                if optimizer_type == 'SGD':\n                    for l_idx, w in enumerate(net.parameters()):\n                        w.data += eta * delta_w_all[l_idx]\n                elif optimizer_type == 'mom':\n                    for l_idx, w in enumerate(net.parameters()):\n                        v_w_all[l_idx] = gamma * v_w_all[l_idx] + eta * delta_w_all[l_idx]\n                        w.data += v_w_all[l_idx]\n\n            # Clear memory to avoid memory leak\n            torch.cuda.empty_cache()\n\n            # Loss calculation\n            loss = criterion(outputs, target)\n            running_loss += loss.item()\n            if i % 100 == 99:  # Print every 100 mini-batches\n                #print(f'Epoch [{epoch+1}], Batch [{i+1}], Loss: {running_loss / 100}')\n                running_loss = 0\n\n        # Validation step at the end of each epoch\n        val_loss, val_accuracy = validate_pepita(net, valloader, device, criterion)\n        print(f'Validation - Epoch [{epoch+1}], Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n\n# Main function to initialize and run training with validation and evaluation\ndef main():\n    config = {\n        'input_size': 28*28,  # MNIST images (28x28)\n        'hidden_sizes': [256, 128],  # Hidden layer sizes\n        'output_size': 10,  # Number of classes (MNIST has 10 classes)\n        'epochs': 50,\n        'learning_rate': 0.01,\n        'momentum': 0.9,\n        'batch_size': 16,\n        'keep_rate': 0.9,\n        'optimizer_type': 'mom',  # Options: 'SGD', 'mom'\n        'lr_decay_epochs': [3],  # Learning rate decay at epoch 3\n        'lr_decay_factor': 0.1  # Factor by which to decay the learning rate\n    }\n    \n    # Initialize network with parameters from config\n    net = PEPITANetwork(config['input_size'], config['hidden_sizes'], config['output_size'])\n    \n    # Load data\n    train_loader, test_loader = get_dataloaders(config['batch_size'])\n    \n    # Train the model with validation\n    train_pepita(net, train_loader, test_loader, config)\n\n    # Evaluate the model on clean data\n    print(\"Evaluating model on clean data...\")\n    evaluate_model(net, test_loader, torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n\n    # Evaluate the model on adversarial examples using PGD\n    print(\"Evaluating model on adversarial data (PGD)...\")\n    evaluate_model(net, test_loader, torch.device('cuda' if torch.cuda.is_available() else 'cpu'), attack_method='PGD')\n\n    # Evaluate the model on adversarial examples using FGSM\n    print(\"Evaluating model on adversarial data (FGSM)...\")\n    evaluate_model(net, test_loader, torch.device('cuda' if torch.cuda.is_available() else 'cpu'), attack_method='FGSM')\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This code defines a function, find_best_learning_rate, that experiments with different learning rates to find the best one based on validation accuracy.","metadata":{}},{"cell_type":"code","source":"def find_best_learning_rate(learning_rates, train_loader, test_loader, config_template):\n    \"\"\"\n    Experiment with different learning rates to find the best one based on validation accuracy.\n    After finding the best model, evaluate it on clean and adversarial examples.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    best_accuracy = 0\n    best_lr = None\n    best_model = None\n    \n    for lr in learning_rates:\n        print(f\"Training with learning rate: {lr}\")\n        # Update config with the current learning rate\n        config = config_template.copy()\n        config['learning_rate'] = lr\n        \n        # Initialize network with parameters from config\n        net = PEPITANetwork(config['input_size'], config['hidden_sizes'], config['output_size'])\n        \n        # Train the model\n        train_pepita(net, train_loader, test_loader, config)\n        \n        # Validate the model on the clean validation set\n        val_loss, val_accuracy = validate_pepita(net, test_loader, device, nn.CrossEntropyLoss())\n        print(f\"Validation accuracy with learning rate {lr}: {val_accuracy:.2f}%\")\n        \n        # Check if this is the best model\n        if val_accuracy > best_accuracy:\n            best_accuracy = val_accuracy\n            best_lr = lr\n            best_model = net\n    \n    print(f\"\\nBest learning rate found: {best_lr} with validation accuracy: {best_accuracy:.2f}%\")\n    \n    # Evaluate the best model on clean data and adversarial data\n    print(\"\\nEvaluating the best model on clean data...\")\n    evaluate_model(best_model, test_loader, device)\n\n    print(\"\\nEvaluating the best model on adversarial data (PGD)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='PGD')\n\n    print(\"\\nEvaluating the best model on adversarial data (FGSM)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='FGSM')\n\n\n# Define the learning rates to experiment with\nlearning_rates = [0.255, 0.016, 0.012, 0.029]\n\n\n# Create the base configuration template\nconfig_template = {\n    'input_size': 28*28,  # MNIST images (28x28)\n    'hidden_sizes': [256, 128],  # Hidden layer sizes\n    'output_size': 10,  # Number of classes (MNIST has 10 classes)\n    'epochs': 50,\n    'learning_rate': 0.01,  # Placeholder, will be updated\n    'momentum': 0.9,\n    'batch_size': 16,\n    'keep_rate': 0.9,\n    'optimizer_type': 'mom',  # Options: 'SGD', 'mom'\n    'lr_decay_epochs': [3],  # Learning rate decay at epoch 3\n    'lr_decay_factor': 0.1  # Factor by which to decay the learning rate\n}\n\n# Load the data\ntrain_loader, test_loader = get_dataloaders(config_template['batch_size'])\n\n# Run the learning rate experiment\nfind_best_learning_rate(learning_rates, train_loader, test_loader, config_template)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This code is an extension of the previous learning rate experimentation but focuses on finding the best learning rate based on adversarial validation accuracy.","metadata":{}},{"cell_type":"code","source":"def find_best_learning_rate_with_adversarial_validation(learning_rates, train_loader, test_loader, config_template, attack_method='PGD'):\n    \"\"\"\n    Experiment with different learning rates to find the best one based on adversarial validation accuracy.\n    After finding the best model, evaluate it on clean and adversarial examples.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    best_accuracy = 0\n    best_lr = None\n    best_model = None\n    \n    for lr in learning_rates:\n        print(f\"Training with learning rate: {lr}\")\n        # Update config with the current learning rate\n        config = config_template.copy()\n        config['learning_rate'] = lr\n        \n        # Initialize network with parameters from config\n        net = PEPITANetwork(config['input_size'], config['hidden_sizes'], config['output_size'])\n        \n        # Train the model\n        train_pepita(net, train_loader, test_loader, config)\n        \n        # Validate the model using adversarial examples\n        print(f\"Validating with adversarial examples ({attack_method})...\")\n        val_accuracy = adversarial_validation(net, test_loader, device, attack_method=attack_method)\n        print(f\"Adversarial validation accuracy with learning rate {lr}: {val_accuracy:.2f}%\")\n        \n        # Check if this is the best model\n        if val_accuracy > best_accuracy:\n            best_accuracy = val_accuracy\n            best_lr = lr\n            best_model = net\n    \n    print(f\"\\nBest learning rate found: {best_lr} with adversarial validation accuracy: {best_accuracy:.2f}%\")\n    \n    # Evaluate the best model on clean data and adversarial data\n    print(\"\\nEvaluating the best model on clean data...\")\n    evaluate_model(best_model, test_loader, device)\n\n    print(\"\\nEvaluating the best model on adversarial data (PGD)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='PGD')\n\n    print(\"\\nEvaluating the best model on adversarial data (FGSM)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='FGSM')\n\n# Function to perform adversarial validation\ndef adversarial_validation(net, dataloader, device, attack_method='PGD'):\n    \"\"\"\n    Perform adversarial validation on the given dataset using the specified attack method.\n    Returns the accuracy on adversarial examples.\n    \"\"\"\n    print(f\"Evaluating adversarial accuracy using {attack_method} attack...\")\n    correct = 0\n    total = 0\n\n    # Set up adversarial attack if specified\n    if attack_method == 'PGD':\n        attack = torchattacks.PGD(net, eps=0.3, alpha=2/255, steps=40)\n    elif attack_method == 'FGSM':\n        attack = torchattacks.FGSM(net, eps=0.3)\n    else:\n        raise ValueError(f\"Unsupported attack method: {attack_method}\")\n\n    net.eval()  # Set network to evaluation mode\n\n    for inputs, target in dataloader:\n        inputs = inputs.view(inputs.size(0), -1).to(device)\n        target = target.to(device)\n\n        # Ensure inputs require gradients for adversarial attack generation\n        inputs.requires_grad_()\n\n        # Apply the adversarial attack\n        inputs = attack(inputs, target)\n\n        # Disable gradient computation for inference\n        with torch.no_grad():\n            outputs = net(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n    accuracy = 100 * correct / total\n    return accuracy\n\n# Define the learning rates to experiment with\nlearning_rates = [0.378, 0.037, 0.025, 0.061]\n\n# Create the base configuration template\nconfig_template = {\n    'input_size': 28*28,  # MNIST images (28x28)\n    'hidden_sizes': [256, 128],  # Hidden layer sizes\n    'output_size': 10,  # Number of classes (MNIST has 10 classes)\n    'epochs': 50,\n    'learning_rate': 0.01,  # Placeholder, will be updated\n    'momentum': 0.9,\n    'batch_size': 16,\n    'keep_rate': 0.9,\n    'optimizer_type': 'mom',  # Options: 'SGD', 'mom'\n    'lr_decay_epochs': [3],  # Learning rate decay at epoch 3\n    'lr_decay_factor': 0.1  # Factor by which to decay the learning rate\n}\n\n# Load the data\ntrain_loader, test_loader = get_dataloaders(config_template['batch_size'])\n\n# Run the learning rate experiment with adversarial validation\nfind_best_learning_rate_with_adversarial_validation(learning_rates, train_loader, test_loader, config_template, attack_method='PGD')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This code introduces adversarial training to enhance the model's robustness by generating adversarial samples during training and evaluates different learning rates to find the best one.","metadata":{}},{"cell_type":"code","source":"# Function for adversarial training\ndef adversarial_train_pepita(net, trainloader, valloader, config, attack_method='PGD'):\n    \"\"\"\n    Train the PEPITA network with adversarial samples.\n    Each batch is augmented with adversarial examples generated by the specified attack method.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    net.to(device)\n\n    # Hyperparameters from config\n    epochs = config['epochs']\n    eta = config['learning_rate']\n    gamma = config['momentum']\n    batch_size = config['batch_size']\n    keep_rate = config['keep_rate']\n    optimizer_type = config['optimizer_type']\n    \n    # Initialize feedback matrix B for MNIST\n    B = initialize_feedback_matrix(28*28, 10, device=device)\n\n    criterion = nn.CrossEntropyLoss()\n\n    # Momentum optimizer setup\n    v_w_all = [torch.zeros(w.shape).to(device) for w in net.parameters()]\n    \n    # Setup adversarial attack\n    if attack_method == 'PGD':\n        attack = torchattacks.PGD(net, eps=0.3, alpha=2/255, steps=40)\n    elif attack_method == 'FGSM':\n        attack = torchattacks.FGSM(net, eps=0.3)\n    else:\n        raise ValueError(f\"Unsupported attack method: {attack_method}\")\n    \n    for epoch in range(epochs):\n        if epoch in config['lr_decay_epochs']:  # Learning rate decay\n            eta *= config['lr_decay_factor']\n        \n        running_loss = 0\n        net.train()  # Set network to training mode\n        \n        for i, data in enumerate(trainloader, 0):\n            inputs, target = data\n            inputs = inputs.view(inputs.size(0), -1).to(device)  # Flatten MNIST input\n            target = target.to(device)  # Move target to device\n            \n            target_onehot = F.one_hot(target, num_classes=10).float().to(device)\n            \n            # Generate adversarial examples for the inputs\n            inputs.requires_grad_()\n            adv_inputs = attack(inputs, target)  # Adversarial inputs\n            \n            # Dropout masks for the two forward passes\n            do_masks = []\n            if keep_rate < 1:\n                for layer in [net.fc1, net.fc2]:\n                    mask = Variable(torch.ones(inputs.shape[0], layer.out_features).bernoulli_(keep_rate)).to(device) / keep_rate\n                    do_masks.append(mask)\n            \n            # Perform forward pass on adversarial examples\n            with torch.no_grad():\n                outputs = net(adv_inputs, do_masks=do_masks)\n                error_signal = outputs - target_onehot\n                error_input = error_signal @ B.T\n                mod_inputs = inputs + error_input\n                mod_outputs = net(mod_inputs, do_masks=do_masks)\n            \n            # Compute weight updates\n            delta_w_all = []\n            for l_idx, layer in enumerate([net.fc1, net.fc2, net.fc3]):\n                if l_idx == 0:\n                    delta_w = -(F.relu(net.fc1(inputs)) - F.relu(net.fc1(mod_inputs))).T @ inputs\n                elif l_idx == 1:\n                    delta_w = -(F.relu(net.fc2(F.relu(net.fc1(inputs)))) - F.relu(net.fc2(F.relu(net.fc1(mod_inputs))))).T @ F.relu(net.fc1(mod_inputs))\n                else:\n                    delta_w = -(error_signal.T @ F.relu(net.fc2(F.relu(net.fc1(mod_inputs)))))\n                delta_w_all.append(delta_w / batch_size)\n\n            # Apply the weight changes\n            if optimizer_type == 'SGD':\n                for l_idx, w in enumerate(net.parameters()):\n                    w.data += eta * delta_w_all[l_idx]\n            elif optimizer_type == 'mom':\n                for l_idx, w in enumerate(net.parameters()):\n                    v_w_all[l_idx] = gamma * v_w_all[l_idx] + eta * delta_w_all[l_idx]\n                    w.data += v_w_all[l_idx]\n\n            # Clear memory to avoid memory leak\n            torch.cuda.empty_cache()\n            \n            # Loss calculation\n            loss = criterion(outputs, target)\n            running_loss += loss.item()\n            if i % 100 == 99:  # Print every 100 mini-batches\n                #print(f'Epoch [{epoch+1}], Batch [{i+1}], Loss: {running_loss / 100}')\n                running_loss = 0\n\n        # Validation step at the end of each epoch\n        val_loss, val_accuracy = validate_pepita(net, valloader, device, criterion)\n        print(f'Validation - Epoch [{epoch+1}], Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n\n# Function to find the best learning rate using adversarial training\ndef find_best_learning_rate_with_adversarial_training(learning_rates, train_loader, test_loader, config_template, attack_method='PGD'):\n    \"\"\"\n    Experiment with different learning rates to find the best one based on natural validation accuracy.\n    After finding the best model, evaluate it on clean and adversarial examples.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    best_accuracy = 0\n    best_lr = None\n    best_model = None\n    \n    for lr in learning_rates:\n        print(f\"\\nTraining with learning rate: {lr}\")\n        # Update config with the current learning rate\n        config = config_template.copy()\n        config['learning_rate'] = lr\n        \n        # Initialize network with parameters from config\n        net = PEPITANetwork(config['input_size'], config['hidden_sizes'], config['output_size'])\n        \n        # Perform adversarial training\n        adversarial_train_pepita(net, train_loader, test_loader, config, attack_method=attack_method)\n        \n        # Validate the model on the clean validation set\n        val_loss, val_accuracy = validate_pepita(net, test_loader, device, nn.CrossEntropyLoss())\n        print(f\"Natural validation accuracy with learning rate {lr}: {val_accuracy:.2f}%\")\n        \n        # Check if this is the best model\n        if val_accuracy > best_accuracy:\n            best_accuracy = val_accuracy\n            best_lr = lr\n            best_model = net\n    \n    print(f\"\\nBest learning rate found: {best_lr} with validation accuracy: {best_accuracy:.2f}%\")\n    \n    # Evaluate the best model on clean data and adversarial data\n    print(\"\\nEvaluating the best model on clean data...\")\n    evaluate_model(best_model, test_loader, device)\n\n    print(\"\\nEvaluating the best model on adversarial data (PGD)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='PGD')\n\n    print(\"\\nEvaluating the best model on adversarial data (FGSM)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='FGSM')\n\n# Define the learning rates to experiment with\nlearning_rates = [0.378, 0.037, 0.025, 0.061]\n\n# Create the base configuration template\nconfig_template = {\n    'input_size': 28*28,  # MNIST images (28x28)\n    'hidden_sizes': [256, 128],  # Hidden layer sizes\n    'output_size': 10,  # Number of classes (MNIST has 10 classes)\n    'epochs': 50,\n    'learning_rate': 0.01,  # Placeholder, will be updated\n    'momentum': 0.9,\n    'batch_size': 16,\n    'keep_rate': 0.9,\n    'optimizer_type': 'mom',  # Options: 'SGD', 'mom'\n    'lr_decay_epochs': [3],  # Learning rate decay at epoch 3\n    'lr_decay_factor': 0.1  # Factor by which to decay the learning rate\n}\n\n# Load the data\ntrain_loader, test_loader = get_dataloaders(config_template['batch_size'])\n\n# Run the learning rate experiment with adversarial training\nfind_best_learning_rate_with_adversarial_training(learning_rates, train_loader, test_loader, config_template, attack_method='PGD')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This code performs fast adversarial training using the FGSM (Fast Gradient Sign Method) to improve model robustness, while experimenting with different learning rates to find the best one based on validation accuracy.","metadata":{}},{"cell_type":"code","source":"# Function for fast adversarial training (FGSM)\ndef fast_adversarial_train_pepita(net, trainloader, valloader, config, attack_method='FGSM'):\n    \"\"\"\n    Train the PEPITA network with FGSM adversarial samples.\n    Each batch is augmented with FGSM-generated adversarial examples.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    net.to(device)\n\n    # Hyperparameters from config\n    epochs = config['epochs']\n    eta = config['learning_rate']\n    gamma = config['momentum']\n    batch_size = config['batch_size']\n    keep_rate = config['keep_rate']\n    optimizer_type = config['optimizer_type']\n    \n    # Initialize feedback matrix B for MNIST\n    B = initialize_feedback_matrix(28*28, 10, device=device)\n\n    criterion = nn.CrossEntropyLoss()\n\n    # Momentum optimizer setup\n    v_w_all = [torch.zeros(w.shape).to(device) for w in net.parameters()]\n    \n    # Setup adversarial attack (FGSM for fast adversarial training)\n    attack = torchattacks.FGSM(net, eps=0.3)\n    \n    for epoch in range(epochs):\n        if epoch in config['lr_decay_epochs']:  # Learning rate decay\n            eta *= config['lr_decay_factor']\n        \n        running_loss = 0\n        net.train()  # Set network to training mode\n        \n        for i, data in enumerate(trainloader, 0):\n            inputs, target = data\n            inputs = inputs.view(inputs.size(0), -1).to(device)  # Flatten MNIST input\n            target = target.to(device)  # Move target to device\n            \n            target_onehot = F.one_hot(target, num_classes=10).float().to(device)\n            \n            # Generate FGSM adversarial examples for the inputs\n            inputs.requires_grad_()\n            adv_inputs = attack(inputs, target)  # FGSM adversarial inputs\n            \n            # Dropout masks for the two forward passes\n            do_masks = []\n            if keep_rate < 1:\n                for layer in [net.fc1, net.fc2]:\n                    mask = Variable(torch.ones(inputs.shape[0], layer.out_features).bernoulli_(keep_rate)).to(device) / keep_rate\n                    do_masks.append(mask)\n            \n            # Perform forward pass on adversarial examples\n            with torch.no_grad():\n                outputs = net(adv_inputs, do_masks=do_masks)\n                error_signal = outputs - target_onehot\n                error_input = error_signal @ B.T\n                mod_inputs = inputs + error_input\n                mod_outputs = net(mod_inputs, do_masks=do_masks)\n            \n            # Compute weight updates\n            delta_w_all = []\n            for l_idx, layer in enumerate([net.fc1, net.fc2, net.fc3]):\n                if l_idx == 0:\n                    delta_w = -(F.relu(net.fc1(inputs)) - F.relu(net.fc1(mod_inputs))).T @ inputs\n                elif l_idx == 1:\n                    delta_w = -(F.relu(net.fc2(F.relu(net.fc1(inputs)))) - F.relu(net.fc2(F.relu(net.fc1(mod_inputs))))).T @ F.relu(net.fc1(mod_inputs))\n                else:\n                    delta_w = -(error_signal.T @ F.relu(net.fc2(F.relu(net.fc1(mod_inputs)))))\n                delta_w_all.append(delta_w / batch_size)\n\n            # Apply the weight changes\n            if optimizer_type == 'SGD':\n                for l_idx, w in enumerate(net.parameters()):\n                    w.data += eta * delta_w_all[l_idx]\n            elif optimizer_type == 'mom':\n                for l_idx, w in enumerate(net.parameters()):\n                    v_w_all[l_idx] = gamma * v_w_all[l_idx] + eta * delta_w_all[l_idx]\n                    w.data += v_w_all[l_idx]\n\n            # Clear memory to avoid memory leak\n            torch.cuda.empty_cache()\n            \n            # Loss calculation\n            loss = criterion(outputs, target)\n            running_loss += loss.item()\n            if i % 100 == 99:  # Print every 100 mini-batches\n                #print(f'Epoch [{epoch+1}], Batch [{i+1}], Loss: {running_loss / 100}')\n                running_loss = 0\n\n        # Validation step at the end of each epoch\n        val_loss, val_accuracy = validate_pepita(net, valloader, device, criterion)\n        print(f'Validation - Epoch [{epoch+1}], Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n\n\n# Function to find the best learning rate with fast adversarial training\ndef find_best_learning_rate_fast_adversarial(learning_rates, train_loader, test_loader, config_template, attack_method='FGSM'):\n    \"\"\"\n    Experiment with different learning rates to find the best one based on natural validation accuracy.\n    After finding the best model, evaluate it on clean and adversarial examples.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    best_accuracy = 0\n    best_lr = None\n    best_model = None\n    \n    for lr in learning_rates:\n        print(f\"\\nTraining with learning rate: {lr}\")\n        # Update config with the current learning rate\n        config = config_template.copy()\n        config['learning_rate'] = lr\n        \n        # Initialize network with parameters from config\n        net = PEPITANetwork(config['input_size'], config['hidden_sizes'], config['output_size'])\n        \n        # Perform fast adversarial training (with FGSM)\n        fast_adversarial_train_pepita(net, train_loader, test_loader, config, attack_method=attack_method)\n        \n        # Validate the model on the clean validation set\n        val_loss, val_accuracy = validate_pepita(net, test_loader, device, nn.CrossEntropyLoss())\n        print(f\"Natural validation accuracy with learning rate {lr}: {val_accuracy:.2f}%\")\n        \n        # Check if this is the best model\n        if val_accuracy > best_accuracy:\n            best_accuracy = val_accuracy\n            best_lr = lr\n            best_model = net\n    \n    print(f\"\\nBest learning rate found: {best_lr} with natural validation accuracy: {best_accuracy:.2f}%\")\n    \n    # Evaluate the best model on clean data and adversarial data\n    print(\"\\nEvaluating the best model on clean data...\")\n    evaluate_model(best_model, test_loader, device)\n\n    print(\"\\nEvaluating the best model on adversarial data (PGD)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='PGD')\n\n    print(\"\\nEvaluating the best model on adversarial data (FGSM)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='FGSM')\n\n# Define the learning rates to experiment with\nlearning_rates = [0.097, 0.027, 0.016, 0.041]\n\n# Create the base configuration template\nconfig_template = {\n    'input_size': 28*28,  # MNIST images (28x28)\n    'hidden_sizes': [256, 128],  # Hidden layer sizes\n    'output_size': 10,  # Number of classes (MNIST has 10 classes)\n    'epochs': 50,\n    'learning_rate': 0.01,  # Placeholder, will be updated\n    'momentum': 0.9,\n    'batch_size': 16,\n    'keep_rate': 0.9,\n    'optimizer_type': 'mom',  # Options: 'SGD', 'mom'\n    'lr_decay_epochs': [3],  # Learning rate decay at epoch 3\n    'lr_decay_factor': 0.1  # Factor by which to decay the learning rate\n}\n\n# Load the data\ntrain_loader, test_loader = get_dataloaders(config_template['batch_size'])\n\n# Run the learning rate experiment with fast adversarial training (FGSM)\nfind_best_learning_rate_fast_adversarial(learning_rates, train_loader, test_loader, config_template, attack_method='FGSM')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BP","metadata":{}},{"cell_type":"markdown","source":"#### This code implements a backpropagation neural network using PyTorch to classify MNIST dataset images, and includes evaluation on both clean and adversarial examples.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport numpy as np\nimport torch.cuda\nimport torchattacks\n\n# Define the backpropagation network\nclass BackpropNetwork(nn.Module):\n    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate=0.1):\n        super(BackpropNetwork, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_sizes[0], bias=False)\n        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1], bias=False)\n        self.fc3 = nn.Linear(hidden_sizes[1], output_size, bias=False)\n        self.dropout_rate = dropout_rate\n        \n        # He initialization\n        fc1_limit = np.sqrt(6.0 / input_size)\n        torch.nn.init.uniform_(self.fc1.weight, a=-fc1_limit, b=fc1_limit)\n        fc2_limit = np.sqrt(6.0 / hidden_sizes[0])\n        torch.nn.init.uniform_(self.fc2.weight, a=-fc2_limit, b=fc2_limit)\n        fc3_limit = np.sqrt(6.0 / hidden_sizes[1])\n        torch.nn.init.uniform_(self.fc3.weight, a=-fc3_limit, b=fc3_limit)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.softmax(self.fc3(x), dim=1)\n        return x\n\n# Setup data loaders (MNIST dataset)\ndef get_dataloaders(batch_size=16):\n    transform = transforms.Compose([transforms.ToTensor()])\n    trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n    testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n    return trainloader, testloader\n\n# Validation function to evaluate model performance\ndef validate_model(net, dataloader, device, criterion):\n    net.eval()  # Set network to evaluation mode\n    running_loss = 0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, target in dataloader:\n            inputs = inputs.view(inputs.size(0), -1).to(device)  # Flatten inputs\n            target = target.to(device)\n            outputs = net(inputs)  # Forward pass\n            loss = criterion(outputs, target)\n            running_loss += loss.item()\n\n            # Accuracy calculation\n            _, predicted = torch.max(outputs.data, 1)\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n    \n    accuracy = 100 * correct / total\n    return running_loss / len(dataloader), accuracy\n\n# Adversarial attack evaluation function\ndef evaluate_model(net, dataloader, device, attack_method=None):\n    net.eval()\n    correct = 0\n    total = 0\n\n    # Set up adversarial attack if specified\n    if attack_method == 'PGD':\n        attack = torchattacks.PGD(net, eps=0.3, alpha=2/255, steps=40)\n    elif attack_method == 'FGSM':\n        attack = torchattacks.FGSM(net, eps=0.3)\n    else:\n        attack = None\n\n    for inputs, target in dataloader:\n        inputs = inputs.view(inputs.size(0), -1).to(device)\n        target = target.to(device)\n\n        if attack:\n            inputs.requires_grad_()\n            inputs = attack(inputs, target) \n\n        with torch.no_grad():\n            outputs = net(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f'Accuracy on {\"adversarial\" if attack else \"clean\"} examples: {accuracy:.2f}%')\n\n# Backpropagation training loop\ndef train_backprop(net, trainloader, valloader, config):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    net.to(device)\n\n    # Hyperparameters from config\n    epochs = config['epochs']\n    eta = config['learning_rate']\n    batch_size = config['batch_size']\n\n    # Use a standard optimizer like SGD with momentum\n    if config['optimizer_type'] == 'SGD':\n        optimizer = torch.optim.SGD(net.parameters(), lr=eta, momentum=config['momentum'])\n    elif config['optimizer_type'] == 'Adam':\n        optimizer = torch.optim.Adam(net.parameters(), lr=eta)\n\n    criterion = nn.CrossEntropyLoss()\n\n    for epoch in range(epochs):\n        if epoch in config['lr_decay_epochs']:  # Learning rate decay\n            for param_group in optimizer.param_groups:\n                param_group['lr'] *= config['lr_decay_factor']\n\n        running_loss = 0\n        net.train()  # Set network to training mode\n        for i, data in enumerate(trainloader, 0):\n            inputs, target = data\n            inputs = inputs.view(inputs.size(0), -1).to(device)  # Flatten MNIST input and move to device\n            target = target.to(device)  # Move target to device\n\n            # Forward pass\n            outputs = net(inputs)\n\n            # Compute loss\n            loss = criterion(outputs, target)\n\n            # Zero gradients, perform backward pass, and update weights\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            if i % 100 == 99:  # Print every 100 mini-batches\n                running_loss = 0\n\n        # Validation step at the end of each epoch\n        val_loss, val_accuracy = validate_model(net, valloader, device, criterion)\n        print(f'Validation - Epoch [{epoch+1}], Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n\n# Main function to initialize and run training with validation and evaluation\ndef main():\n    config = {\n        'input_size': 28*28,  # MNIST images (28x28)\n        'hidden_sizes': [256, 128],  # Hidden layer sizes\n        'output_size': 10,  # Number of classes (MNIST has 10 classes)\n        'epochs': 50,\n        'learning_rate': 0.01,\n        'momentum': 0.9,\n        'batch_size': 16,\n        'optimizer_type': 'SGD',  # Options: 'SGD', 'Adam'\n        'lr_decay_epochs': [3],  # Learning rate decay at epoch 3\n        'lr_decay_factor': 0.1  # Factor by which to decay the learning rate\n    }\n    \n    # Initialize network with parameters from config\n    net = BackpropNetwork(config['input_size'], config['hidden_sizes'], config['output_size'])\n    \n    # Load data\n    train_loader, test_loader = get_dataloaders(config['batch_size'])\n    \n    # Train the model with validation\n    train_backprop(net, train_loader, test_loader, config)\n\n    # Evaluate the model on clean data\n    print(\"Evaluating model on clean data...\")\n    evaluate_model(net, test_loader, torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n\n    # Evaluate the model on adversarial examples using PGD\n    print(\"Evaluating model on adversarial data (PGD)...\")\n    evaluate_model(net, test_loader, torch.device('cuda' if torch.cuda.is_available() else 'cpu'), attack_method='PGD')\n\n    # Evaluate the model on adversarial examples using FGSM\n    print(\"Evaluating model on adversarial data (FGSM)...\")\n    evaluate_model(net, test_loader, torch.device('cuda' if torch.cuda.is_available() else 'cpu'), attack_method='FGSM')\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This code performs a learning rate search for the Backpropagation Network to determine the best learning rate based on validation accuracy.","metadata":{}},{"cell_type":"code","source":"def find_best_learning_rate(learning_rates, train_loader, test_loader, config_template):\n    \"\"\"\n    Experiment with different learning rates to find the best one based on validation accuracy.\n    After finding the best model, evaluate it on clean and adversarial examples.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    best_accuracy = 0\n    best_lr = None\n    best_model = None\n    \n    for lr in learning_rates:\n        print(f\"Training with learning rate: {lr}\")\n        # Update config with the current learning rate\n        config = config_template.copy()\n        config['learning_rate'] = lr\n        \n        # Initialize network with parameters from config\n        net = BackpropNetwork(config['input_size'], config['hidden_sizes'], config['output_size'])\n        \n        # Train the model\n        train_backprop(net, train_loader, test_loader, config)\n        \n        # Validate the model on the clean validation set\n        val_loss, val_accuracy = validate_model(net, test_loader, device, nn.CrossEntropyLoss())\n        print(f\"Validation accuracy with learning rate {lr}: {val_accuracy:.2f}%\")\n        \n        # Check if this is the best model\n        if val_accuracy > best_accuracy:\n            best_accuracy = val_accuracy\n            best_lr = lr\n            best_model = net\n    \n    print(f\"\\nBest learning rate found: {best_lr} with validation accuracy: {best_accuracy:.2f}%\")\n    \n    # Evaluate the best model on clean data and adversarial data\n    print(\"\\nEvaluating the best model on clean data...\")\n    evaluate_model(best_model, test_loader, device)\n\n    print(\"\\nEvaluating the best model on adversarial data (PGD)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='PGD')\n\n    print(\"\\nEvaluating the best model on adversarial data (FGSM)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='FGSM')\n\n\n# Define the learning rates to experiment with\nlearning_rates = [0.123, 0.051, 0.008, 0.035]\n\n\n# Create the base configuration template\nconfig_template = {\n    'input_size': 28*28,  # MNIST images (28x28)\n    'hidden_sizes': [256, 128],  # Hidden layer sizes\n    'output_size': 10,  # Number of classes (MNIST has 10 classes)\n    'epochs': 50,\n    'learning_rate': 0.01,  # Placeholder, will be updated\n    'momentum': 0.9,\n    'batch_size': 16,\n    'optimizer_type': 'SGD',  # Options: 'SGD', 'Adam'\n    'lr_decay_epochs': [3],  # Learning rate decay at epoch 3\n    'lr_decay_factor': 0.1  # Factor by which to decay the learning rate\n}\n\n# Load the data\ntrain_loader, test_loader = get_dataloaders(config_template['batch_size'])\n\n# Run the learning rate experiment\nfind_best_learning_rate(learning_rates, train_loader, test_loader, config_template)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This code extends the learning rate search by incorporating adversarial validation to find the best learning rate for a model that can resist adversarial attacks. The key additions are the validation on adversarial examples and the evaluation of model performance based on adversarial accuracy.","metadata":{}},{"cell_type":"code","source":"def find_best_learning_rate_with_adversarial_validation(learning_rates, train_loader, test_loader, config_template, attack_method='PGD'):\n    \"\"\"\n    Experiment with different learning rates to find the best one based on adversarial validation accuracy.\n    After finding the best model, evaluate it on clean and adversarial examples.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    best_accuracy = 0\n    best_lr = None\n    best_model = None\n    \n    for lr in learning_rates:\n        print(f\"Training with learning rate: {lr}\")\n        # Update config with the current learning rate\n        config = config_template.copy()\n        config['learning_rate'] = lr\n        \n        # Initialize network with parameters from config\n        net = BackpropNetwork(config['input_size'], config['hidden_sizes'], config['output_size'])\n        \n        # Train the model\n        train_backprop(net, train_loader, test_loader, config)\n        \n        # Validate the model using adversarial examples\n        print(f\"Validating with adversarial examples ({attack_method})...\")\n        val_accuracy = adversarial_validation(net, test_loader, device, attack_method=attack_method)\n        print(f\"Adversarial validation accuracy with learning rate {lr}: {val_accuracy:.2f}%\")\n        \n        # Check if this is the best model\n        if val_accuracy > best_accuracy:\n            best_accuracy = val_accuracy\n            best_lr = lr\n            best_model = net\n    \n    print(f\"\\nBest learning rate found: {best_lr} with adversarial validation accuracy: {best_accuracy:.2f}%\")\n    \n    # Evaluate the best model on clean data and adversarial data\n    print(\"\\nEvaluating the best model on clean data...\")\n    evaluate_model(best_model, test_loader, device)\n\n    print(\"\\nEvaluating the best model on adversarial data (PGD)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='PGD')\n\n    print(\"\\nEvaluating the best model on adversarial data (FGSM)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='FGSM')\n\n# Function to perform adversarial validation\ndef adversarial_validation(net, dataloader, device, attack_method='PGD'):\n    \"\"\"\n    Perform adversarial validation on the given dataset using the specified attack method.\n    Returns the accuracy on adversarial examples.\n    \"\"\"\n    print(f\"Evaluating adversarial accuracy using {attack_method} attack...\")\n    correct = 0\n    total = 0\n\n    # Set up adversarial attack if specified\n    if attack_method == 'PGD':\n        attack = torchattacks.PGD(net, eps=0.3, alpha=2/255, steps=40)\n    elif attack_method == 'FGSM':\n        attack = torchattacks.FGSM(net, eps=0.3)\n    else:\n        raise ValueError(f\"Unsupported attack method: {attack_method}\")\n\n    net.eval()  # Set network to evaluation mode\n\n    for inputs, target in dataloader:\n        inputs = inputs.view(inputs.size(0), -1).to(device)\n        target = target.to(device)\n\n        # Ensure inputs require gradients for adversarial attack generation\n        inputs.requires_grad_()\n\n        # Apply the adversarial attack\n        inputs = attack(inputs, target)\n\n        # Disable gradient computation for inference\n        with torch.no_grad():\n            outputs = net(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n    accuracy = 100 * correct / total\n    return accuracy\n\n# Define the learning rates to experiment with\nlearning_rates = [0.378, 0.273, 0.039, 0.180]\n\n# Create the base configuration template\nconfig_template = {\n    'input_size': 28*28,  # MNIST images (28x28)\n    'hidden_sizes': [256, 128],  # Hidden layer sizes\n    'output_size': 10,  # Number of classes (MNIST has 10 classes)\n    'epochs': 50,\n    'learning_rate': 0.01,  # Placeholder, will be updated\n    'momentum': 0.9,\n    'batch_size': 16,\n    'optimizer_type': 'SGD',  # Options: 'SGD', 'Adam'\n    'lr_decay_epochs': [3],  # Learning rate decay at epoch 3\n    'lr_decay_factor': 0.1  # Factor by which to decay the learning rate\n}\n\n# Load the data\ntrain_loader, test_loader = get_dataloaders(config_template['batch_size'])\n\n# Run the learning rate experiment with adversarial validation\nfind_best_learning_rate_with_adversarial_validation(learning_rates, train_loader, test_loader, config_template, attack_method='PGD')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This code introduces adversarial training using either the PGD (Projected Gradient Descent) or FGSM (Fast Gradient Sign Method) attack methods to improve the model's robustness. The function find_best_learning_rate_with_adversarial_training is used to identify the best learning rate based on validation accuracy","metadata":{}},{"cell_type":"code","source":"import torchattacks\n\n# Function for adversarial training using backpropagation\ndef adversarial_train_backprop(net, trainloader, valloader, config, attack_method='PGD'):\n    \"\"\"\n    Train the network with adversarial samples using backpropagation.\n    Each batch is augmented with adversarial examples generated by the specified attack method.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    net.to(device)\n\n    # Hyperparameters from config\n    epochs = config['epochs']\n    eta = config['learning_rate']\n    batch_size = config['batch_size']\n\n    # Use a standard optimizer like SGD with momentum\n    if config['optimizer_type'] == 'SGD':\n        optimizer = torch.optim.SGD(net.parameters(), lr=eta, momentum=config['momentum'])\n    elif config['optimizer_type'] == 'Adam':\n        optimizer = torch.optim.Adam(net.parameters(), lr=eta)\n\n    criterion = nn.CrossEntropyLoss()\n\n    # Setup adversarial attack\n    if attack_method == 'PGD':\n        attack = torchattacks.PGD(net, eps=0.3, alpha=2/255, steps=40)\n    elif attack_method == 'FGSM':\n        attack = torchattacks.FGSM(net, eps=0.3)\n    else:\n        raise ValueError(f\"Unsupported attack method: {attack_method}\")\n\n    for epoch in range(epochs):\n        if epoch in config['lr_decay_epochs']:  # Learning rate decay\n            for param_group in optimizer.param_groups:\n                param_group['lr'] *= config['lr_decay_factor']\n        \n        running_loss = 0\n        net.train()  # Set network to training mode\n        \n        for i, data in enumerate(trainloader, 0):\n            inputs, target = data\n            inputs = inputs.view(inputs.size(0), -1).to(device)  # Flatten MNIST input\n            target = target.to(device)  # Move target to device\n            \n            # Generate adversarial examples for the inputs\n            inputs.requires_grad_()\n            adv_inputs = attack(inputs, target)  # Adversarial inputs\n            \n            # Perform forward pass on adversarial examples\n            optimizer.zero_grad()  # Zero out the previous gradients\n            outputs = net(adv_inputs)\n            loss = criterion(outputs, target)  # Compute loss\n            loss.backward()  # Backpropagate the loss\n            optimizer.step()  # Update weights\n\n            running_loss += loss.item()\n            if i % 100 == 99:  # Print every 100 mini-batches\n                #print(f'Epoch [{epoch+1}], Batch [{i+1}], Loss: {running_loss / 100:.4f}')\n                running_loss = 0\n\n        # Validation step at the end of each epoch\n        val_loss, val_accuracy = validate_model(net, valloader, device, criterion)\n        print(f'Validation - Epoch [{epoch+1}], Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n\n# Function to find the best learning rate using adversarial training\ndef find_best_learning_rate_with_adversarial_training(learning_rates, train_loader, test_loader, config_template, attack_method='PGD'):\n    \"\"\"\n    Experiment with different learning rates to find the best one based on natural validation accuracy.\n    After finding the best model, evaluate it on clean and adversarial examples.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    best_accuracy = 0\n    best_lr = None\n    best_model = None\n    \n    for lr in learning_rates:\n        print(f\"\\nTraining with learning rate: {lr}\")\n        # Update config with the current learning rate\n        config = config_template.copy()\n        config['learning_rate'] = lr\n        \n        # Initialize network with parameters from config\n        net = BackpropNetwork(config['input_size'], config['hidden_sizes'], config['output_size'])\n        \n        # Perform adversarial training\n        adversarial_train_backprop(net, train_loader, test_loader, config, attack_method=attack_method)\n        \n        # Validate the model on the clean validation set\n        val_loss, val_accuracy = validate_model(net, test_loader, device, nn.CrossEntropyLoss())\n        print(f\"Natural validation accuracy with learning rate {lr}: {val_accuracy:.2f}%\")\n        \n        # Check if this is the best model\n        if val_accuracy > best_accuracy:\n            best_accuracy = val_accuracy\n            best_lr = lr\n            best_model = net\n    \n    print(f\"\\nBest learning rate found: {best_lr} with validation accuracy: {best_accuracy:.2f}%\")\n    \n    # Evaluate the best model on clean data and adversarial data\n    print(\"\\nEvaluating the best model on clean data...\")\n    evaluate_model(best_model, test_loader, device)\n\n    print(\"\\nEvaluating the best model on adversarial data (PGD)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='PGD')\n\n    print(\"\\nEvaluating the best model on adversarial data (FGSM)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='FGSM')\n\n# Define the learning rates to experiment with\nlearning_rates = [0.052, 0.030, 0.012, 0.014]\n\n# Create the base configuration template\nconfig_template = {\n    'input_size': 28*28,  # MNIST images (28x28)\n    'hidden_sizes': [256, 128],  # Hidden layer sizes\n    'output_size': 10,  # Number of classes (MNIST has 10 classes)\n    'epochs': 50,\n    'learning_rate': 0.01,  # Placeholder, will be updated\n    'momentum': 0.9,\n    'batch_size': 16,\n    'optimizer_type': 'SGD',  # Options: 'SGD', 'Adam'\n    'lr_decay_epochs': [3],  # Learning rate decay at epoch 3\n    'lr_decay_factor': 0.1  # Factor by which to decay the learning rate\n}\n\n# Load the data\ntrain_loader, test_loader = get_dataloaders(config_template['batch_size'])\n\n# Run the learning rate experiment with adversarial training\nfind_best_learning_rate_with_adversarial_training(learning_rates, train_loader, test_loader, config_template, attack_method='PGD')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This code performs fast adversarial training using FGSM (Fast Gradient Sign Method) with backpropagation, and experiments with different learning rates to find the best one. It evaluates the model based on both natural (clean) and adversarial examples.","metadata":{}},{"cell_type":"code","source":"import torchattacks\n\n# Function for fast adversarial training (FGSM) using backpropagation\ndef fast_adversarial_train_backprop(net, trainloader, valloader, config, attack_method='FGSM'):\n    \"\"\"\n    Train the network with FGSM adversarial samples using backpropagation.\n    Each batch is augmented with FGSM-generated adversarial examples.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    net.to(device)\n\n    # Hyperparameters from config\n    epochs = config['epochs']\n    eta = config['learning_rate']\n    batch_size = config['batch_size']\n\n    # Use a standard optimizer like SGD with momentum\n    if config['optimizer_type'] == 'SGD':\n        optimizer = torch.optim.SGD(net.parameters(), lr=eta, momentum=config['momentum'])\n    elif config['optimizer_type'] == 'Adam':\n        optimizer = torch.optim.Adam(net.parameters(), lr=eta)\n\n    criterion = nn.CrossEntropyLoss()\n\n    # Setup adversarial attack (FGSM for fast adversarial training)\n    attack = torchattacks.FGSM(net, eps=0.3)\n\n    for epoch in range(epochs):\n        if epoch in config['lr_decay_epochs']:  # Learning rate decay\n            for param_group in optimizer.param_groups:\n                param_group['lr'] *= config['lr_decay_factor']\n\n        running_loss = 0\n        net.train()  # Set network to training mode\n        \n        for i, data in enumerate(trainloader, 0):\n            inputs, target = data\n            inputs = inputs.view(inputs.size(0), -1).to(device)  # Flatten MNIST input\n            target = target.to(device)  # Move target to device\n            \n            # Generate FGSM adversarial examples for the inputs\n            inputs.requires_grad_()\n            adv_inputs = attack(inputs, target)  # FGSM adversarial inputs\n            \n            # Perform forward pass on adversarial examples\n            optimizer.zero_grad()  # Zero out previous gradients\n            outputs = net(adv_inputs)  # Forward pass with adversarial inputs\n            loss = criterion(outputs, target)  # Compute loss\n            loss.backward()  # Backpropagate the loss\n            optimizer.step()  # Update weights\n\n            running_loss += loss.item()\n            if i % 100 == 99:  # Print every 100 mini-batches\n                #print(f'Epoch [{epoch+1}], Batch [{i+1}], Loss: {running_loss / 100:.4f}')\n                running_loss = 0\n\n        # Validation step at the end of each epoch\n        val_loss, val_accuracy = validate_model(net, valloader, device, criterion)\n        print(f'Validation - Epoch [{epoch+1}], Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n\n\n# Function to find the best learning rate with fast adversarial training (FGSM)\ndef find_best_learning_rate_fast_adversarial(learning_rates, train_loader, test_loader, config_template, attack_method='FGSM'):\n    \"\"\"\n    Experiment with different learning rates to find the best one based on natural validation accuracy.\n    After finding the best model, evaluate it on clean and adversarial examples.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    best_accuracy = 0\n    best_lr = None\n    best_model = None\n    \n    for lr in learning_rates:\n        print(f\"\\nTraining with learning rate: {lr}\")\n        # Update config with the current learning rate\n        config = config_template.copy()\n        config['learning_rate'] = lr\n        \n        # Initialize network with parameters from config\n        net = BackpropNetwork(config['input_size'], config['hidden_sizes'], config['output_size'])\n        \n        # Perform fast adversarial training (with FGSM)\n        fast_adversarial_train_backprop(net, train_loader, test_loader, config, attack_method=attack_method)\n        \n        # Validate the model on the clean validation set\n        val_loss, val_accuracy = validate_model(net, test_loader, device, nn.CrossEntropyLoss())\n        print(f\"Natural validation accuracy with learning rate {lr}: {val_accuracy:.2f}%\")\n        \n        # Check if this is the best model\n        if val_accuracy > best_accuracy:\n            best_accuracy = val_accuracy\n            best_lr = lr\n            best_model = net\n    \n    print(f\"\\nBest learning rate found: {best_lr} with natural validation accuracy: {best_accuracy:.2f}%\")\n    \n    # Evaluate the best model on clean data and adversarial data\n    print(\"\\nEvaluating the best model on clean data...\")\n    evaluate_model(best_model, test_loader, device)\n\n    print(\"\\nEvaluating the best model on adversarial data (PGD)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='PGD')\n\n    print(\"\\nEvaluating the best model on adversarial data (FGSM)...\")\n    evaluate_model(best_model, test_loader, device, attack_method='FGSM')\n\n\n# Define the learning rates to experiment with\nlearning_rates = [0.097, 0.010, 0.012, 0.027]\n\n# Create the base configuration template\nconfig_template = {\n    'input_size': 28*28,  # MNIST images (28x28)\n    'hidden_sizes': [256, 128],  # Hidden layer sizes\n    'output_size': 10,  # Number of classes (MNIST has 10 classes)\n    'epochs': 50,\n    'learning_rate': 0.01,  # Placeholder, will be updated\n    'momentum': 0.9,\n    'batch_size': 16,\n    'optimizer_type': 'SGD',  # Options: 'SGD', 'Adam'\n    'lr_decay_epochs': [3],  # Learning rate decay at epoch 3\n    'lr_decay_factor': 0.1  # Factor by which to decay the learning rate\n}\n\n# Load the data\ntrain_loader, test_loader = get_dataloaders(config_template['batch_size'])\n\n# Run the learning rate experiment with fast adversarial training (FGSM)\nfind_best_learning_rate_fast_adversarial(learning_rates, train_loader, test_loader, config_template, attack_method='FGSM')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}